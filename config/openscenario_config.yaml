# OpenSCENARIO 2.0 RAG System Configuration
system:
  name: "OpenSCENARIO-RAG"
  version: "1.0.0"
  environment: "production"
  
# Hardware configuration for 8x A100 setup
hardware:
  gpu_count: 8
  gpu_memory_per_device: "80GB"
  cuda_version: "12.1"
  use_gpu_acceleration: true
  device_map: "auto"

# Model configurations
models:
  codellama:
    name: "codellama/CodeLlama-13b-Instruct-hf"
    path: "data/models/codellama-13b"
    precision: "fp16"
    quantization: "8bit"
    max_length: 4096
    temperature: 0.3
    top_p: 0.9
    device_map: "auto"
    
  open_model:
    name: "WizardLM/WizardCoder-15B-V1.0"
    path: "data/models/wizardcoder-15b"
    precision: "fp16"
    quantization: "8bit"
    max_length: 4096
    temperature: 0.3
    top_p: 0.9
    device_map: "auto"

# Embedding model for retrieval
embedding:
  model_name: "microsoft/codebert-base"
  model_path: "data/models/codebert-base"
  batch_size: 32
  max_length: 512
  normalize_embeddings: true

# Document processing
document_processing:
  chunk_size: 800
  chunk_overlap: 100
  pdf_parser: "langextract"
  extract_tables: true
  extract_code_blocks: true
  preserve_formatting: true

# Data paths
data:
  documentation_pdf: "data/docs/ASAM-OpenSCENARIO-2.0.pdf"
  code_examples_dir: "data/examples/"
  processed_chunks_dir: "data/processed/"
  embeddings_cache_dir: "data/embeddings/"
  models_dir: "data/models/"

# Vector store configuration
vector_store:
  type: "faiss"
  index_type: "IndexFlatIP"  # Inner product for cosine similarity
  use_gpu: true
  gpu_devices: [0, 1, 2, 3]  # Use first 4 GPUs for FAISS
  dimension: 768
  cache_embeddings: true
  
# BM25 sparse retrieval
bm25:
  k1: 1.2
  b: 0.75
  cache_index: true

# Hybrid retrieval settings
retrieval:
  top_k_dense: 20
  top_k_sparse: 15
  top_k_final: 10
  dense_weight: 0.7
  sparse_weight: 0.3
  tag_boost_factor: 1.5
  rerank: true
  rerank_model: "cross-encoder/ms-marco-MiniLM-L-6-v2"

# Code generation settings
generation:
  max_tokens: 1024
  min_tokens: 50
  temperature: 0.2
  top_p: 0.9
  repetition_penalty: 1.1
  stop_sequences: ["</code>", "# End", "```"]
  
# OpenSCENARIO parser validation
validation:
  parser_command: "py-osc2"
  max_retries: 3
  timeout_seconds: 30
  enable_feedback_loop: true

# Caching configuration
cache:
  type: "redis"
  host: "localhost"
  port: 6379
  db: 0
  ttl_seconds: 86400  # 24 hours
  enable_disk_cache: true
  disk_cache_dir: "data/cache/"
  max_cache_size: "10GB"

# Performance optimizations
performance:
  batch_size: 8
  num_workers: 4
  prefetch_factor: 2
  pin_memory: true
  compile_model: true
  use_flash_attention: true
  gradient_checkpointing: false

# Monitoring and logging
monitoring:
  enable_metrics: true
  metrics_port: 8000
  log_level: "INFO"
  log_file: "logs/openscenario_rag.log"
  track_performance: true
  
# API configuration
api:
  host: "0.0.0.0"
  port: 5000
  debug: false
  max_content_length: "100MB"
  request_timeout: 300

# Tag system for code examples
tags:
  categories:
    - "cut-in"
    - "parallel_drive"
    - "lane_change"
    - "overtaking"
    - "parking"
    - "intersection"
    - "traffic_light"
    - "pedestrian"
    - "weather"
    - "road_conditions"
  boost_tagged_results: true
  tag_weight_multiplier: 1.3
